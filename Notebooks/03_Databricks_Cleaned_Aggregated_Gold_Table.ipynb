{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db19d42b-5f66-4a2d-9859-ea87029e54e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Access key replaced with placeholder inorder to publish this notebook into github\n",
    "spark.conf.set(\n",
    "\"fs.azure.account.key.goodreadsreviews60104758.dfs.core.windows.net\",\n",
    "\"<access key>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4af156d5-3015-47f9-b464-a7b770f57183",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+---------+---------------+--------------------+------+--------------------+-------------+-------+--------------------+\n",
      "|           review_id| book_id|               title|author_id|           name|             user_id|rating|         review_text|language_code|n_votes|          date_added|\n",
      "+--------------------+--------+--------------------+---------+---------------+--------------------+------+--------------------+-------------+-------+--------------------+\n",
      "|3818908d5a98733ba...|17282103|    هكذا تكلم زرادشت|   196327|     Jody Rosen|b72b9ef6b43e415ee...|     3|hkdh tklm zrdsht ...|          ara|      3|Sat Feb 09 11:01:...|\n",
      "|a04023de2a39a2cab...|   35350|What the Body Rem...|    35285|Jimmy McDonough|b9c1edf6bcc9b1819...|     3|Read this for a c...|          eng|      0|Mon Sep 23 10:23:...|\n",
      "|092beaa2de4ea5a77...|   92146|Carved in Bone (B...|    88874|    Cris Freddi|6e1d7ac0a6e738b23...|     5|It is two years s...|        en-US|      0|Mon Nov 10 11:54:...|\n",
      "|ba230623304ed18ee...|  389897|The Princess With...|   379511|Marlys Mayfield|c1a90329852cc999e...|     3|I took some brief...|             |      2|Tue Dec 30 20:03:...|\n",
      "|f7988518dccbfe64b...|  327548|    The Walking Drum|   116584|  Allan Safarik|881ca71192c9dddb8...|     4|So, my rating of ...|             |      1|Tue Sep 24 06:45:...|\n",
      "+--------------------+--------+--------------------+---------+---------------+--------------------+------+--------------------+-------------+-------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Path to your curated Gold dataset\n",
    "gold_path = \"abfss://lakehouse@goodreadsreviews60104758.dfs.core.windows.net/lakehouse/gold/curated_reviews\"\n",
    "\n",
    "# Load the Delta table into a Spark DataFrame\n",
    "df = spark.read.table(\"gold.curated_reviews\")\n",
    "\n",
    "# Preview the data\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc12ed4b-ed3f-4fe1-a770-73519191a52c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- author_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- review_text: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- n_votes: long (nullable = true)\n",
      " |-- date_added: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking the data types\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d32f59ad-7391-4b50-8185-f8c81769e184",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#fixing the data types\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "df = df.withColumn(\"rating\", df[\"rating\"].cast(IntegerType()))\n",
    "df = df.withColumn(\"n_votes\", df[\"n_votes\"].cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b1fd1bf-e9d7-4262-8af6-edcfd2301b60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- author_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- review_text: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- n_votes: integer (nullable = true)\n",
      " |-- date_added: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a2473b9-520e-4b71-bae3-1b79a5ab93f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|date_added                    |\n",
      "+------------------------------+\n",
      "|Sat Feb 09 11:01:35 -0800 2013|\n",
      "|Mon Sep 23 10:23:54 -0700 2013|\n",
      "|Mon Nov 10 11:54:40 -0800 2008|\n",
      "|Tue Dec 30 20:03:15 -0800 2008|\n",
      "|Tue Sep 24 06:45:34 -0700 2013|\n",
      "+------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Show a sample of the date_added column\n",
    "df.select(\"date_added\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3743bf5d-3ca7-4852-9909-9323bc5b0480",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# covnert date_added to iso format and name it date_added_iso and then change its data type to date\n",
    "from pyspark.sql.functions import regexp_extract, concat_ws, col\n",
    "\n",
    "# Extract year, month, day using regex\n",
    "df = df.withColumn(\"year\", regexp_extract(col(\"date_added\"), r\"\\d{4}$\", 0)) \\\n",
    "       .withColumn(\"month_str\", regexp_extract(col(\"date_added\"), r\"\\b(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\b\", 0)) \\\n",
    "       .withColumn(\"day\", regexp_extract(col(\"date_added\"), r\"\\b\\d{2}\\b\", 0))\n",
    "\n",
    "# Map month names to numbers\n",
    "month_dict = {\n",
    "    \"Jan\":\"01\",\"Feb\":\"02\",\"Mar\":\"03\",\"Apr\":\"04\",\"May\":\"05\",\"Jun\":\"06\",\n",
    "    \"Jul\":\"07\",\"Aug\":\"08\",\"Sep\":\"09\",\"Oct\":\"10\",\"Nov\":\"11\",\"Dec\":\"12\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1506be9-89a0-48a1-87d9-5a2af72052c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------------+\n",
      "|date_added                    |date_added_iso|\n",
      "+------------------------------+--------------+\n",
      "|Sat Feb 09 11:01:35 -0800 2013|2013-02-09    |\n",
      "|Mon Sep 23 10:23:54 -0700 2013|2013-09-23    |\n",
      "|Mon Nov 10 11:54:40 -0800 2008|2008-11-10    |\n",
      "|Tue Dec 30 20:03:15 -0800 2008|2008-12-30    |\n",
      "|Tue Sep 24 06:45:34 -0700 2013|2013-09-24    |\n",
      "+------------------------------+--------------+\n",
      "only showing top 5 rows\n",
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- author_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- review_text: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- n_votes: integer (nullable = true)\n",
      " |-- date_added: string (nullable = true)\n",
      " |-- date_added_iso: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import create_map, lit\n",
    "from itertools import chain\n",
    "\n",
    "mapping_expr = create_map([lit(x) for x in chain(*month_dict.items())])\n",
    "df = df.withColumn(\"month\", mapping_expr[col(\"month_str\")])\n",
    "\n",
    "# Combine into yyyy-mm-dd and cast to date\n",
    "df = df.withColumn(\"date_added_iso\", concat_ws(\"-\", col(\"year\"), col(\"month\"), col(\"day\")).cast(\"date\"))\n",
    "\n",
    "# Drop intermediate columns if you want\n",
    "df = df.drop(\"year\", \"month_str\", \"day\", \"month\")\n",
    "\n",
    "# Show result\n",
    "df.select(\"date_added\", \"date_added_iso\").show(5, truncate=False)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a152c542-9def-4d2d-ab21-9cab9691ed32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE cleaning: 788770 rows\n"
     ]
    }
   ],
   "source": [
    "before_count = df.count()\n",
    "print(f\"BEFORE cleaning: {before_count} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0695845-d7eb-4247-99f6-0df781aa9d69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER removing NULLs: 788770 rows\n",
      "AFTER removing empty strings: 788770 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, trim\n",
    "# Remove nulls\n",
    "df = df.dropna(subset=[\"rating\", \"book_id\", \"review_text\", \"author_id\"])\n",
    "after_null = df.count()\n",
    "print(f\"AFTER removing NULLs: {after_null} rows\")\n",
    "\n",
    "# Remove EMPTY STRINGS\n",
    "df = df.filter(\n",
    "    (col(\"rating\").isNotNull()) &\n",
    "    (trim(col(\"book_id\")) != \"\") &\n",
    "    (trim(col(\"review_text\")) != \"\") &\n",
    "    (trim(col(\"author_id\")) != \"\")\n",
    ")\n",
    "after_empty = df.count()\n",
    "print(f\"AFTER removing empty strings: {after_empty} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4be3ae6b-b275-4ea1-8f6d-af6aabe4246c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER removing review_id duplicates: 788770 rows\n",
      "AFTER removing (user_id, book_id) duplicates: 788770 rows\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicates\n",
    "df = df.dropDuplicates([\"review_id\"])\n",
    "after_review_id = df.count()\n",
    "print(f\"AFTER removing review_id duplicates: {after_review_id} rows\")\n",
    "\n",
    "df = df.dropDuplicates([\"user_id\", \"book_id\"])\n",
    "after_user_book = df.count()\n",
    "print(f\"AFTER removing (user_id, book_id) duplicates: {after_user_book} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9338b4d2-3191-4c52-b590-036363b4f5d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Trim text fields\n",
    "df = df.withColumn(\"title\", trim(col(\"title\"))) \\\n",
    "       .withColumn(\"name\", trim(col(\"name\"))) \\\n",
    "       .withColumn(\"review_text\", trim(col(\"review_text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e31b6b57-13e8-4f74-9d5f-c4e867bec9da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|review_text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|re-read this before starting go set a watchman. hadn't read in many years. had even forgotten some of the finer points. glad i did!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|ambientada en un futuro en el que el mundo se ha estructurado en entidades cuasi-nacionales organizadas por franquicias y en el que internet ha dado paso al metaverso, \"snow crash\" supone el primer exito en la bibliografia de neal stephenson. autor que ya mostraba por entonces, 1992, conocimientos enciclopedicos. no en vano la novela conjuga estetica cyberpunk, realidad virtual, mitologia sumeria y linguistica estructural y anticipa el interes del escritor norteamericano por los temas filosoficos, desarrollados en posteriores obras. \"snow crash\" supone, por tanto, una de sus novelas mas accesibles y entretenidas y presagia las joyas que estarian aun por llegar.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "|lucy has such a strong, unwavering voice.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "|i cannot believe that it took the release of the film interpretation of this novel for me to discover this book. all the more shocking is the fact that i took a \"history of the slave narrative\" class in university; yet still this book, and the gruesome fact that freed black citizens were kidnapped and sold into slavery, slipped under my radar. no longer though!  it really is wonderful that there is a film to bring awareness to the real story, written in vivid, tragic details by freed man turned slave solomon northup; while some doubt the truth of northup's story, i am confident in the search for truth mentioned in a slate article (shown below) and other sources.  found throughout this book is an undying faith, possessed by solomon, that he will someday be saved, while the sinners will be punished, and the good rewarded with freedom and the promise of heaven. given the weight of the subject matter, the book is surprisingly accessible. perhaps it is because at times, northup takes a break from his own narrative to explain aspects of slave life that northern readers may not have known upon discovering the book. how-to's on the cycles of the fields, from cotton to corn, and on the daily life of the plantation slaves, owners, and guests, make this narrative particularly educational.  do yourself a favor; read this book. it should be discovered by high schoolers across the u.s. and belongs on the same bookshelf as frederick douglass' own slave narrative; harriet jacobs' life of a slave girl; and the fictional uncle tom's cabin.  http://www.slate.com/blogs/browbeat/2...|\n",
      "|it seems most fantasy novels are much darker than this one. it was a great story. i look forward to reading more by this author. 5 stars.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lower, regexp_replace\n",
    "# Normalize review_text\n",
    "\n",
    "df = df.withColumn(\"review_text\", lower(col(\"review_text\"))) \\\n",
    "       .withColumn(\"review_text\", regexp_replace(col(\"review_text\"), \"[^\\\\x20-\\\\x7E]\", \"\"))\n",
    "\n",
    "# Preview result\n",
    "df.select(\"review_text\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56ccb150-bb68-4f5c-b5aa-a21b2e3dc9c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+----------------------+\n",
      "|title                                        |name                  |\n",
      "+---------------------------------------------+----------------------+\n",
      "|To Kill A Mockingbird                        |Lito Fernandez        |\n",
      "|Snow Crash                                   |Deborah Woodward      |\n",
      "|Lucy                                         |Jeff Slayton          |\n",
      "|Twelve Years A Slave                         |Susan Schindehette    |\n",
      "|The Way Of Kings (the Stormlight Archive, #1)|Matthew Ryan Defibaugh|\n",
      "+---------------------------------------------+----------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import initcap, col\n",
    "\n",
    "# Capitalize each word in title and name\n",
    "df = df.withColumn(\"title\", initcap(col(\"title\"))) \\\n",
    "       .withColumn(\"name\", initcap(col(\"name\")))\n",
    "\n",
    "# Preview result\n",
    "df.select(\"title\", \"name\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccee81da-0189-4a9a-9b0a-c0adfd2c435e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|review_length|\n",
      "+-------------+\n",
      "|586          |\n",
      "|2053         |\n",
      "|91           |\n",
      "|485          |\n",
      "|37           |\n",
      "+-------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Create review lenght column to count number of characters in review\n",
    "from pyspark.sql.functions import length, col\n",
    "df = df.withColumn(\"review_length\", length(col(\"review_text\")))\n",
    "\n",
    "df.select(\"review_length\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af2ce538-b43e-47c0-92d7-e601987a6a9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after filtering: 788769\n"
     ]
    }
   ],
   "source": [
    "before_count = df.count()\n",
    "df = df.filter(col(\"review_length\") >= 10)\n",
    "after_count = df.count()\n",
    "print(f\"Number of rows after filtering: {after_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31dfee89-294c-4b4b-a3ad-25db18fbc109",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, current_date\n",
    "# Remove rows with invalid or future dates\n",
    "df = df.filter(\n",
    "    (col(\"date_added_iso\").isNotNull()) &\n",
    "    (col(\"date_added_iso\") <= current_date())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e15625e-c160-4f52-a2cc-0cd2e3b8886a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "# Replacing missing n_votes with value 0\n",
    "df = df.fillna({\"n_votes\": 0})\n",
    "\n",
    "# Replace null or empty language_code with \"Unknown\"\n",
    "df = df.withColumn(\n",
    "    \"language_code\",\n",
    "    when((col(\"language_code\").isNull()) | (col(\"language_code\") == \"\"), \"Unknown\")\n",
    "    .otherwise(col(\"language_code\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37b160bc-c68f-434f-8fe9-aba73dcc91ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'review_id' has 0 null values\n",
      "Column 'book_id' has 0 null values\n",
      "Column 'title' has 0 null values\n",
      "Column 'author_id' has 0 null values\n",
      "Column 'name' has 0 null values\n",
      "Column 'user_id' has 0 null values\n",
      "Column 'rating' has 0 null values\n",
      "Column 'review_text' has 0 null values\n",
      "Column 'language_code' has 0 null values\n",
      "Column 'n_votes' has 0 null values\n",
      "Column 'date_added' has 0 null values\n",
      "Column 'date_added_iso' has 0 null values\n",
      "Column 'review_length' has 0 null values\n"
     ]
    }
   ],
   "source": [
    "# Loop through all columns and count nulls and Verify that all columns contain valid values\n",
    "for c in df.columns:\n",
    "    null_count = df.filter(col(c).isNull()).count()\n",
    "    print(f\"Column '{c}' has {null_count} null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fa856ee-a991-4cc1-949e-1de04a79bac0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'title' has 0 empty strings\n",
      "Column 'name' has 0 empty strings\n",
      "Column 'review_text' has 0 empty strings\n",
      "Column 'language_code' has 0 empty strings\n"
     ]
    }
   ],
   "source": [
    "text_cols = [\"title\", \"name\", \"review_text\", \"language_code\"]\n",
    "for c in text_cols:\n",
    "    empty_count = df.filter(col(c) == \"\").count()\n",
    "    print(f\"Column '{c}' has {empty_count} empty strings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f198a39-e6c5-4fcc-8ace-88be3890db65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- author_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- review_text: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- n_votes: integer (nullable = false)\n",
      " |-- date_added: string (nullable = true)\n",
      " |-- date_added_iso: date (nullable = true)\n",
      " |-- review_length: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show schema to verify types and check column names\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36dd2493-bff3-4bb0-98e1-e94f03f5dd56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['review_id',\n",
       " 'book_id',\n",
       " 'title',\n",
       " 'author_id',\n",
       " 'name',\n",
       " 'user_id',\n",
       " 'rating',\n",
       " 'review_text',\n",
       " 'language_code',\n",
       " 'n_votes',\n",
       " 'date_added_iso']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the unnecessary columns\n",
    "df = df.drop(\"date_added\", \"review_length\")\n",
    "\n",
    "# Check remaining columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1b800f5-a6a7-438c-92c1-839ca63bfdc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid ratings: 0\n",
      "Negative votes: 57\n"
     ]
    }
   ],
   "source": [
    "#Verify that all numeric columns contain valid values and within expected ranges\n",
    "# Check RATING (1-5)\n",
    "invalid_rating = df.filter((col(\"rating\") < 1) | (col(\"rating\") > 5)).count()\n",
    "print(f\"Invalid ratings: {invalid_rating}\")\n",
    "\n",
    "# ============================================================\n",
    "# N_VOTES: Can be negative (downvotes/dislikes)\n",
    "# Negative votes might represent downvotes or \"not helpful\" votes\n",
    "# ============================================================\n",
    "invalid_votes = df.filter(col(\"n_votes\") < 0).count()\n",
    "print(f\"Negative votes: {invalid_votes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a442ccd4-cccb-4ae0-8a4a-872ed073653b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|         review_text|review_word_count|\n",
      "+--------------------+-----------------+\n",
      "|more of an academ...|               10|\n",
      "|          230 - 2015|                3|\n",
      "|i liked this. it ...|               14|\n",
      "|intrigado com ess...|              140|\n",
      "|what's to say? an...|               38|\n",
      "+--------------------+-----------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Add Aggregate columns\n",
    "# Compute review length in words\n",
    "from pyspark.sql.functions import length, split, size, col\n",
    "df = df.withColumn('review_word_count', size(split(col('review_text'), ' ')))\n",
    "df.select('review_text', 'review_word_count').show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea1437ba-af3b-4eab-beeb-1093aa7fb197",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+--------------------+\n",
      "| book_id|avg_book_rating|num_reviews_per_book|\n",
      "+--------+---------------+--------------------+\n",
      "|    6194|            4.0|                 131|\n",
      "|15772440|            4.0|                   1|\n",
      "|  133241|           4.26|                 123|\n",
      "|  169338|           4.57|                  28|\n",
      "|17160066|           3.83|                  23|\n",
      "+--------+---------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, count, round\n",
    "# Group by book_id and calculate aggregates\n",
    "book_features = (\n",
    "    df.groupBy(\"book_id\")\n",
    "      .agg(\n",
    "          round(avg(\"rating\"), 2).alias(\"avg_book_rating\"),\n",
    "          count(\"review_id\").alias(\"num_reviews_per_book\")\n",
    "      )\n",
    ")\n",
    "# Show first few rows\n",
    "book_features.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "776414d0-fe3b-4c1f-9427-49b5fa768b35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|                name|author_avg_rating|\n",
      "+--------------------+-----------------+\n",
      "|         Iola Fuller|             3.76|\n",
      "|Richard Roger Van...|             4.06|\n",
      "|    Robert R. Mccrae|             3.69|\n",
      "|      Robert Hampson|             3.15|\n",
      "|     Edwin M. Curley|              4.0|\n",
      "+--------------------+-----------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Average rating per Author\n",
    "author_avg = (\n",
    "    df.groupBy(\"name\")\n",
    "      .agg(\n",
    "          round(avg(\"rating\"), 2).alias(\"author_avg_rating\")\n",
    "      )\n",
    ")\n",
    "author_avg.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78cab786-445a-4004-bfd1-d85de26908f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+------------------+------------------+\n",
      "| book_id|min_words_per_book|max_words_per_book|avg_words_per_book|\n",
      "+--------+------------------+------------------+------------------+\n",
      "|    6194|                 2|              1231|            150.32|\n",
      "|15772440|                46|                46|              46.0|\n",
      "|  133241|                 2|               841|              88.0|\n",
      "|  169338|                 4|               704|            142.64|\n",
      "|17160066|                 9|              1089|            152.57|\n",
      "+--------+------------------+------------------+------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, round, min as spark_min, max as spark_max, col, size, split\n",
    "\n",
    "word_stats_per_book = df.groupBy('book_id').agg(\n",
    "    spark_min('review_word_count').alias('min_words_per_book'),\n",
    "    spark_max('review_word_count').alias('max_words_per_book'),\n",
    "    round(avg('review_word_count'), 2).alias('avg_words_per_book')\n",
    ")\n",
    "\n",
    "word_stats_per_book.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ea54130-5d46-4a83-921a-a8021515c176",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join book-level features (avg rating & num reviews)\n",
    "df = df.join(book_features, on='book_id', how='left')\n",
    "\n",
    "# Join author-level average rating\n",
    "df = df.join(author_avg, on='name', how='left')\n",
    "\n",
    "# Join word count statistics per book\n",
    "df = df.join(word_stats_per_book, on='book_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7aff7f43-bd7c-4ca3-9a8f-1d45b1592e44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# drop helper column\n",
    "df = df.drop('review_word_count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a379a7b4-0f3f-4c8f-b805-9a61b92cc4fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"num_reviews_per_book\", df[\"num_reviews_per_book\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13722c60-6057-42fc-bf99-48f341e93e90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final columns: 17\n",
      "root\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- author_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- review_text: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- n_votes: integer (nullable = false)\n",
      " |-- date_added_iso: date (nullable = true)\n",
      " |-- avg_book_rating: double (nullable = true)\n",
      " |-- num_reviews_per_book: integer (nullable = true)\n",
      " |-- author_avg_rating: double (nullable = true)\n",
      " |-- min_words_per_book: integer (nullable = true)\n",
      " |-- max_words_per_book: integer (nullable = true)\n",
      " |-- avg_words_per_book: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final columns: {len(df.columns)}\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "573ab09a-640c-4d0d-8ba9-2ce4a695b8ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the Gold layer path where the Delta table will be stored\n",
    "gold_path_new  = \"abfss://lakehouse@goodreadsreviews60104758.dfs.core.windows.net/lakehouse/gold/features_v1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51cf9f9d-0f08-435f-a1c2-9a0fdc9f7b39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the DataFrame as a Delta table in the Gold path\n",
    "# mode='overwrite' ensures that if the table already exists, it will be replaced\n",
    "df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(gold_path_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f953aeaf-4802-4627-8184-a1b0f14231a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+---------+--------------------+------+--------------------+-------------+-------+--------------+---------------+--------------------+-----------------+------------------+------------------+------------------+\n",
      "| book_id|                name|           review_id|               title|author_id|             user_id|rating|         review_text|language_code|n_votes|date_added_iso|avg_book_rating|num_reviews_per_book|author_avg_rating|min_words_per_book|max_words_per_book|avg_words_per_book|\n",
      "+--------+--------------------+--------------------+--------------------+---------+--------------------+------+--------------------+-------------+-------+--------------+---------------+--------------------+-----------------+------------------+------------------+------------------+\n",
      "|   12067|Catherine Van Moppes|20950466ccbdaa041...|Good Omens: The N...|  4110990|118bfe1cc97da3ea6...|     5|i've already read...|          eng|      0|    2008-11-09|           4.08|                2168|             4.06|                 1|              1202|              78.8|\n",
      "|   69719|        Jeff Slayton|dbddc4c69756a1af5...|                Lucy|  1109454|64207c4e06d209b65...|     3|lucy has such a s...|          fre|      1|    2015-03-29|            3.7|                  44|             3.64|                 4|               738|            103.75|\n",
      "|18478222|  Susan Schindehette|64b70354c3cd5adee...|Twelve Years A Slave|   160246|431a9f3726e1ddd6f...|     5|i cannot believe ...|          eng|      0|    2014-01-22|           4.22|                 426|             4.25|                 1|              1344|            105.65|\n",
      "| 4502877|        Lex Lesgever|6f8a62b618f0fe4b0...|Midnight Sun (twi...|  4551869|b052db6070ee63ced...|     1|edward was the on...|          eng|      0|    2015-01-28|           4.18|                1534|             4.18|                 1|              1908|             55.76|\n",
      "| 7235533|Matthew Ryan Defi...|c0fa93748b611f345...|The Way Of Kings ...|  8134945|86200cf9b14206ddf...|     5|it seems most fan...|          eng|      0|    2014-12-26|           4.56|                1919|             4.55|                 1|              1751|            137.19|\n",
      "+--------+--------------------+--------------------+--------------------+---------+--------------------+------+--------------------+-------------+-------+--------------+---------------+--------------------+-----------------+------------------+------------------+------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Register the Delta table in the Databricks metastore for SQL queries\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS gold.features_v1\n",
    "USING DELTA\n",
    "LOCATION '{gold_path_new}'\n",
    "\"\"\")\n",
    "\n",
    "# Show a few rows to verify the saved dataset\n",
    "df.show(5)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Goodreads-Cleaning-Gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
